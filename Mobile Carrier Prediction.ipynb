{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile carrier Megaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this endeavor, we embark on a mission to assist Mobile carrier Megaline in optimizing their customer plans. Faced with the challenge of numerous customers still using legacy plans, our goal is to develop an advanced model that leverages behavior data. This model will not only analyze customer behavior but also recommend the ideal plan from Megaline's newer offerings: Smart or Ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration: Begin by opening and thoroughly examining the dataset located at the path 'datasets/users_behavior.csv.' Download the dataset for further analysis.\n",
    "\n",
    "Data Splitting: Divide the source data into three distinct sets: a training set, a validation set, and a test set. These sets will serve as the foundation for model development and evaluation.\n",
    "\n",
    "Model Investigation: Explore the quality and performance of various machine learning models by systematically altering hyperparameters. Document the results of this experimentation, providing concise descriptions of the key findings.\n",
    "\n",
    "Model Assessment: Evaluate the performance of the selected model using the test set to ensure its predictive accuracy and effectiveness.\n",
    "\n",
    "Additional Task (Sanity Check): Recognize that this dataset presents a higher level of complexity than previous data. Conduct a comprehensive analysis to assess the model's sanity and robustness, addressing any challenges and intricacies encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* сalls — number of calls,\n",
    "* minutes — total call duration in minutes,\n",
    "* messages — number of text messages,\n",
    "* mb_used — Internet traffic used in MB,\n",
    "* is_ultra — plan for the current month (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowload the data and Prepare it for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the first 500 rows of data from visits_log_us.csv \n",
    "try:\n",
    "    users=pd.read_csv('/datasets/users_behavior.csv')\n",
    "except:\n",
    "    users=pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#describe the data\n",
    "users.describe()\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information about the dataset.There are no missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicated\n",
    "print(users.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data sets\n",
    "user_train, user_valid_and_test = train_test_split(users, test_size=0.4, random_state=12345)\n",
    "user_valid, user_test = train_test_split(user_valid_and_test, test_size=0.5, random_state=12345)\n",
    "\n",
    "features_train = user_train.drop(['is_ultra'], axis=1)\n",
    "target_train = user_train['is_ultra']\n",
    "\n",
    "features_valid = user_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = user_valid['is_ultra']\n",
    "\n",
    "features_test = user_test.drop(['is_ultra'], axis=1)\n",
    "target_test = user_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Depth  Validation Accuracy\n",
      "0      1             0.754277\n",
      "1      2             0.782271\n",
      "2      3             0.785381\n",
      "3      4             0.779160\n",
      "4      5             0.779160\n",
      "5      6             0.783826\n",
      "6      7             0.782271\n",
      "7      8             0.779160\n",
      "8      9             0.782271\n",
      "9     10             0.774495\n"
     ]
    }
   ],
   "source": [
    "# Define the depth range\n",
    "depth_range=range(1,11)\n",
    "#Initialize a list\n",
    "decision_tree_results=[]\n",
    "#loop through the depth and train the model\n",
    "for depth in depth_range:\n",
    "    model_dt=DecisionTreeClassifier(max_depth=depth,random_state=12345)\n",
    "    model_dt.fit(features_train,target_train)\n",
    "    # calculate accuracy\n",
    "    valid_accuracy = model_dt.score(features_valid, target_valid)\n",
    "    \n",
    "    # Append results to the list\n",
    "    decision_tree_results.append({'Depth': depth, 'Validation Accuracy': valid_accuracy})\n",
    "\n",
    "# Convert results to a DataFrame for analysis\n",
    "decision_tree_df = pd.DataFrame(decision_tree_results)\n",
    "\n",
    "# Display the results\n",
    "print(decision_tree_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the depth of the decision tree increases from 1 to 3, the validation accuracy also increases. This suggests that the model becomes more capable of capturing complex patterns in the data, resulting in improved accuracy.\n",
    "\n",
    "Around depths 3 to 6, the validation accuracy hovers around 0.78, but it doesn't show significant improvement. This could indicate that the model reaches a plateau in terms of accuracy gains, and increasing complexity beyond a certain point doesn't provide substantial benefits.\n",
    "\n",
    "After depth 6, the accuracy begins to decrease slightly. This could be a sign of overfitting. Overfitting occurs when a model becomes too complex, fitting the training data noise rather than the underlying patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Estimators: 10, Validation Accuracy: 0.79\n",
      "Number of Estimators: 20, Validation Accuracy: 0.79\n",
      "Number of Estimators: 30, Validation Accuracy: 0.78\n",
      "Number of Estimators: 40, Validation Accuracy: 0.78\n",
      "Number of Estimators: 50, Validation Accuracy: 0.79\n",
      "Number of Estimators: 60, Validation Accuracy: 0.79\n",
      "Number of Estimators: 70, Validation Accuracy: 0.78\n",
      "Number of Estimators: 80, Validation Accuracy: 0.78\n",
      "Number of Estimators: 90, Validation Accuracy: 0.78\n",
      "Number of Estimators: 100, Validation Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Define a range of estimator values (number of trees)\n",
    "estimator_range = range(10, 101, 10)\n",
    "\n",
    "# Initialize a list to store accuracy scores for each estimator value\n",
    "accuracy_scores = []\n",
    "\n",
    "# Iterate through the estimator values\n",
    "for n_estimators in estimator_range:\n",
    "    # Create a Random Forest model with the current number of estimators\n",
    "    random_forest_model = RandomForestClassifier(n_estimators=n_estimators, random_state=12345)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    random_forest_model.fit(features_train, target_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    predictions_valid = random_forest_model.predict(features_valid)\n",
    "    \n",
    "    # Calculate the accuracy of the model on the validation set\n",
    "    accuracy_valid = accuracy_score(target_valid, predictions_valid)\n",
    "    \n",
    "    # Append the accuracy score to the list\n",
    "    accuracy_scores.append(accuracy_valid)\n",
    "    \n",
    "    # Print the validation accuracy for the current number of estimators\n",
    "    print(f\"Number of Estimators: {n_estimators}, Validation Accuracy: {accuracy_valid:.2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the n_estimators increases, so does the accuracy on the training stay within 0.79 to 0.78.Based on this observation, \n",
    "The accuracy on the validation set stops improving after n_estimators of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the best train model we obtain in the previous section, we will use a model of Random Forest with a n_estimators of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the train set: 0.9797717842323651\n",
      "Accuracy of the best model on the validation set: 0.7651632970451011\n",
      "Accuracy of the best model on the test set: 0.776049766718507\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "print('Accuracy of the best model on the train set:', model.score(features_train, target_train))\n",
    "print('Accuracy of the best model on the validation set:', model.score(features_valid, target_valid))\n",
    "print('Accuracy of the best model on the test set:', model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the test 77%  This project has met the threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
